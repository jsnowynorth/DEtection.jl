

"""
    Model Structure

Initiates a structure of class Model

# Arguments
- T
- N
- D
- Î½T
- bufferTime
- batchTime
- learning_rate
- Z
- U
- Basis
- States
- Î›::Function: Library of potential functions
- Î›names::Vector{String}: Names of components of library of potential functions

"""
mutable struct Model

  # model
  # S, T, N, D, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, Z, U, Basis, States

  # dimensions
  T::Int
  L::Int
  N::Int
  D::Int

  # data parameters
  Î½T
  buffer
  batch_size
  TimeStep
  learning_rate
  inner_inds

  # data
  V::Array{Float64}
  H
  X

  # basis functions
  Basis::DerivativeClass

  # function information
  Î›::Function
  Î›TimeNames::Vector{String}

  # SSVS parameters
  v0::Float64
  v1::Float64

  function_names
  response

end

Base.show(io::IO, model::Model) =
  print(io, "Model\n",
    " â”œâ”€â”€â”€ data dimensions: ", [model.T, model.L], '\n',
    " â”œâ”€â”€â”€ process dimensions: ", [model.T, model.N], '\n',
    " â”œâ”€â”€â”€ response: ", model.response, '\n',
    " â”œâ”€â”€â”€ library: ", model.function_names, '\n',
    " â”œâ”€â”€â”€ covariates: ", model.X === nothing ? false : size(model.X, 1), '\n',
    " â”œâ”€â”€â”€ temporal domain: ", model.TimeStep, '\n',
    " â”œâ”€â”€â”€ number of temporal basis functions: ", model.Î½T, '\n',
    " â”œâ”€â”€â”€ SSVS parameters: v0 = " * string(model.v0) * ", v1 = " * string(model.v1), '\n',
    " â”œâ”€â”€â”€ learning rate: ", model.learning_rate, '\n',
    " â”œâ”€â”€â”€ time buffer: ", model.buffer, '\n',
    " â””â”€â”€â”€ time batch size: ", model.batch_size)
#

"""
    Pars Structure

Initiates a structure of class Pars

# Arguments
- A: basis coefficients
- M: PDE coefficients
- Î£Z : measurement variance/covariance matrix
- Î£U: process variance/covariance matrix
- gamma: ssvs latent parameters
- sample_inds: current subsampled indicies for SGD
- F: current F
- Fprime: current Fprime
- a_R
- A_R
- nu_R
- a_Q
- A_Q
- nu_Q
- v0
- v1
- Sigma_M

"""
mutable struct Pars

  # parameters
  # A, M, Î£Y, Î£U, gamma, F, a_R, A_R, nu_R, a_Q, A_Q, nu_Q, v0, v1, Sigma_M

  # estimated parameters
  A::Array{Float64}
  M::Array{Float64}
  Î£V::Array{Float64}
  Î£U::Array{Float64}
  gamma::Array{Int}

  # current value of function
  sample_inds::Vector{Int}
  F
  Fprime
  State::StateClass

  # hyperpriors
  a_V
  A_V
  nu_V::Int

  a_U
  A_U
  nu_U::Int

  # SSVS parameters
  Î£M::Array{Float64}
  Ï€

end

"""
    Posterior Struct

Initiates a structure of class Posterior to hold posterior samples

# Arguments

"""
mutable struct Posterior

  M
  gamma
  Î£V
  Î£U
  A
  Ï€

end


"""
    make_H(M, N, one_inds)

Used to construct the mapping matrix H for missing data

"""
function make_H(L, N, one_inds)
  H_tmp = zeros(L, N)
  H_tmp[diagind(H_tmp)] .= one_inds
  return H_tmp
end

"""
    create_pars()

Constructs the parameter and model classes.
"""
function create_pars(Y::Array{Float64,2},
  TimeStep::Vector,
  nbasis::Int,
  buffer::Int,
  batch_size::Int,
  learning_rate::Float64,
  v0::Float64,
  v1::Float64,
  Î›::Function,
  Î›Names::Vector{String};
  degree = 4, orderTime = 1, latent_dim = size(Y, 1), covariates = nothing)

  L = size(Y, 1)
  T = size(Y, 2)
  N = latent_dim # need to update

  V = Y

  inner_inds = (buffer):(T-buffer-1)

  if covariates === nothing
    X = nothing
  else
    X = reduce(vcat, [reshape(covs[:, :, i], 1, :) for i in 1:size(covs, 3)])
  end

  # get missing values - no missing here
  H = ones(L, T)
  H = [make_H(L, N, H[:, i]) for i in 1:(T)]

  # basis functions
  Basis = derivatives_dictionary(orderTime, nbasis, TimeStep, degree = degree)

  Î¦ = Basis.TimeDerivative[Basis.TimeNames[1]]
  A = copy((inv(Î¦'*Î¦) * Î¦' * V')')

  State = construct_state(A, Basis)

  # parameters
  samp_inds = sample(inner_inds, batch_size, replace = false)
  F = create_Î›(Î›, A, Basis, Î›Names, X)
  dF = create_âˆ‡Î›(Î›, A, Basis, samp_inds, Î›Names, X)

  D = size(F, 2)
  M = zeros(N, D)
  Î£V = Diagonal(ones(N))
  Î£U = Diagonal(ones(N))

  # hyperpriors
  a_V = ones(N)
  A_V = fill(1e6, N)
  nu_V = 2

  a_U = ones(N)
  A_U = fill(1e6, N)
  nu_U = 2

  # SSVS parameters
  gamma = ones(N, D)
  Î£M = Diagonal([(vec(gamma)[i] == 1 ? v1 : v0) for i in 1:(D*N)])
  Ï€ = 0.5 * ones(N)


  Î¦tmp = [Basis.TimeDerivative[Î›Names[i]] for i in 1:length(Î›Names)]
  if X === nothing
    function_names = replace((@code_string Î›(A, Î¦tmp)).string[findfirst("return", (@code_string Î›(A, Î¦tmp)).string)[end]+2:end], "\n    " => " ", "\n" => "", "end" => "", "[" => "", "]" => "", "." => "")
  else
    function_names = replace((@code_string Î›(A, Î¦tmp, X)).string[findfirst("return", (@code_string Î›(A, Î¦tmp, X)).string)[end]+2:end], "\n    " => " ", "\n" => "", "end" => "", "[" => "", "]" => "", "." => "")
  end

  response = State.StateNames[end]

  # store model and parameter values
  model = Model(T, L, N, D, nbasis, buffer, batch_size, TimeStep, learning_rate, inner_inds, V, H, X, Basis, Î›, Î›Names, v0, v1, function_names, response)
  pars = Pars(A, M, Î£V, Î£U, gamma, samp_inds, F, dF, State, a_V, A_V, nu_V, a_U, A_U, nu_U, Î£M, Ï€)

  return pars, model

end # fully observed data

function create_pars(Y::Array{Union{Missing,Float64},2},
  TimeStep::Vector,
  nbasis::Int,
  buffer::Int,
  batch_size::Int,
  learning_rate::Float64,
  v0::Float64,
  v1::Float64,
  Î›::Function,
  Î›Names::Vector{String};
  degree = 4, orderTime = 1, latent_dim = size(Y, 1), covariates = nothing)

  L = size(Y, 1)
  T = size(Y, 2)
  N = latent_dim # need to update

  V = collect(Missings.replace(Y, 0)) # convert to Float64

  inner_inds = (buffer):(T-buffer-1)

  if covariates === nothing
    X = nothing
  else
    X = reduce(vcat, [reshape(covs[:, :, i], 1, :) for i in 1:size(covs, 3)])
  end

  # get missing values - no missing here
  # na_inds = getindex.(findall(ismissing, Y), 2)
  na_inds = hcat(getindex.(findall(ismissing, Y), 1), getindex.(findall(ismissing, Y), 2))
  H = ones(L, T)
  if (size(na_inds)[1] != 0)
    H[na_inds[:,1], na_inds[:,2]] .= 0
  end
  H = [make_H(L, N, H[:, i]) for i in 1:(T)]

  # construct data for inital guess, not saved for sampled
  VM = copy(Y)
  tmp_ind = hcat(getindex.(findall(ismissing, VM), 1), getindex.(findall(ismissing, VM), 2))
  if tmp_ind[1,2] == 1
    tmp_ind[1,2] = 3
  end
  tmp_ind[:,2] = tmp_ind[:,2] .- 1

  VM[na_inds[:,1], na_inds[:,2]] = VM[tmp_ind[:,1], tmp_ind[:,2]]
  still_missing = hcat(getindex.(findall(ismissing, VM), 1), getindex.(findall(ismissing, VM),2))
  while size(still_missing, 1) > 1
    tmp_ind = copy(still_missing)
    tmp_ind[:,2] = tmp_ind[:,2] .- 1
    VM[still_missing[:,1], still_missing[:,2]] = VM[tmp_ind[:,1], tmp_ind[:,2]]
    still_missing = hcat(getindex.(findall(ismissing, VM), 1), getindex.(findall(ismissing, VM),2))
  end

  VM = convert(Matrix{Float64}, VM) # not saved



  # basis functions
  Basis = derivatives_dictionary(orderTime, nbasis, TimeStep, degree = degree)

  Î¦ = Basis.TimeDerivative[Basis.TimeNames[1]]
  # A = copy((inv(Î¦'*Î¦) * Î¦' * V')')
  A = copy((inv(Î¦'*Î¦) * Î¦' * VM')')

  State = construct_state(A, Basis)

  # parameters
  samp_inds = sample(inner_inds, batch_size, replace = false)
  F = create_Î›(Î›, A, Basis, Î›Names, X)
  dF = create_âˆ‡Î›(Î›, A, Basis, samp_inds, Î›Names, X)

  D = size(F, 2)
  M = zeros(N, D)
  Î£V = Diagonal(ones(N))
  Î£U = Diagonal(ones(N))

  # hyperpriors
  a_V = ones(N)
  A_V = fill(1e6, N)
  nu_V = 2

  a_U = ones(N)
  A_U = fill(1e6, N)
  nu_U = 2

  # SSVS parameters
  gamma = ones(N, D)
  Î£M = Diagonal([(vec(gamma)[i] == 1 ? v1 : v0) for i in 1:(D*N)])
  Ï€ = 0.5 * ones(N)


  Î¦tmp = [Basis.TimeDerivative[Î›Names[i]] for i in 1:length(Î›Names)]
  if X === nothing
    function_names = replace((@code_string Î›(A, Î¦tmp)).string[findfirst("return", (@code_string Î›(A, Î¦tmp)).string)[end]+2:end], "\n    " => " ", "\n" => "", "end" => "", "[" => "", "]" => "", "." => "")
  else
    function_names = replace((@code_string Î›(A, Î¦tmp, X)).string[findfirst("return", (@code_string Î›(A, Î¦tmp, X)).string)[end]+2:end], "\n    " => " ", "\n" => "", "end" => "", "[" => "", "]" => "", "." => "")
  end

  response = State.StateNames[end]

  # store model and parameter values
  model = Model(T, L, N, D, nbasis, buffer, batch_size, TimeStep, learning_rate, inner_inds, V, H, X, Basis, Î›, Î›Names, v0, v1, function_names, response)
  pars = Pars(A, M, Î£V, Î£U, gamma, samp_inds, F, dF, State, a_V, A_V, nu_V, a_U, A_U, nu_U, Î£M, Ï€)

  return pars, model

end # missing data




"""
    update_M!(pars)

Used within sgmcmc() function.
Gibbs step for M.
"""
function update_M!(pars, model)

  V = (pars.F[model.inner_inds, :]' âŠ— I(model.N)) * (Diagonal(ones(length(model.inner_inds))) âŠ— inv(pars.Î£U)) * transpose(pars.F[model.inner_inds, :]' âŠ— I(model.N)) + inv(pars.Î£M)
  a = (pars.F[model.inner_inds, :]' âŠ— I(model.N)) * (Diagonal(ones(length(model.inner_inds))) âŠ— inv(pars.Î£U)) * vec(pars.State.State[model.response][:,model.inner_inds])

  C = cholesky(Hermitian(V))
  b = rand(Normal(0.0, 1.0), model.N * model.D)

  pars.M = reshape(C.U \ ((C.L \ a) + b), model.N, :)

  return pars
end



"""
    update_gamma!(pars)

Used within sgmcmc() function.
Gibbs step for latent SSVS variables.
"""
function update_gamma!(pars, model)
  
  p1 = pdf.(Normal(0, sqrt(model.v1)), pars.M) .* pars.Ï€
  p0 = pdf.(Normal(0, sqrt(model.v0)), pars.M) .* (1 .- pars.Ï€)
  p = p1 ./ (p1 + p0)
  p = replace!(p, NaN => 0)

  pars.gamma = rand.(Binomial.(1, p))
  pars.Î£M = Diagonal([(vec(pars.gamma)[i] == 1 ? model.v1 : model.v0) for i in 1:(model.D*model.N)])
  # for i in 1:model.N
  #   pars.Ï€[i] = rand(Beta(1 + sum(pars.gamma[i, :]), 1 + sum(1 .- pars.gamma[i, :])))
  # end

  return pars
end


"""
  update_Î£V!(pars)

Used within sgmcmc() function.
Gibbs step for measurement error.
"""
function update_Î£V!(pars, model)

  sse_tmp = [model.V[:, j] - model.H[j] * pars.State.State[pars.State.StateNames[1]][:, j] for j in model.inner_inds]
  sse_tmp = reduce(hcat, sse_tmp)
  for n in 1:model.N
    a_hat = (length(model.inner_inds) + pars.nu_V) / 2
    b_hat = (0.5*(sse_tmp[n, :]'*sse_tmp[n, :])+pars.nu_V[1]/pars.a_V[n])[1]
    pars.Î£V[n,n] = rand(InverseGamma(a_hat, b_hat))
  end

  for n in 1:model.N
    a_hat = (pars.nu_V + 1) / 2
    b_hat = (pars.nu_V / pars.Î£V[n]) + (1 / pars.A_V[n]^2)
    pars.a_V[n] = rand(InverseGamma(a_hat, b_hat))
  end

  return pars
end


"""
  update_Î£U!(pars)

Used within sgmcmc() function.
Gibbs step for process error.
"""
function update_Î£U!(pars, model)

  Uprime = pars.State.State[model.response][:,model.inner_inds]
  
  nu_hat = pars.nu_U + model.N + length(model.inner_inds) - 1
  Phi_hat = 2 * pars.nu_U * Diagonal(1 ./ pars.a_U) + (Uprime - pars.M * pars.F[model.inner_inds,:]') * transpose(Uprime - pars.M * pars.F[model.inner_inds,:]')
  pars.Î£U = rand(InverseWishart(nu_hat, cholesky(Hermitian(Phi_hat))))

  a_hat = (pars.nu_U + model.N) / 2
  for n in 1:model.N
    b_hat = (pars.nu_U / pars.Î£U[n, n]) + (1 / pars.A_U[n]^2)
    pars.a_U[n] = rand(InverseGamma(a_hat, b_hat))
  end

  return pars
end



"""
  Î”L(z, H, Ïˆ, gÏˆ, Ï•, Ï•_t, Î˜, Î£Zinv, Î£Uinv, A, M, fcurr, fprime)

Used within DEtection() function.
Calculates the gradient of the log likelihood.
"""
function Î”L(v, H, Ï•, Ï•_t, Î£Vinv, Î£Uinv, A, M, fcurr, fprime)

  Î”L = -H' * Î£Vinv * v * Ï•' +
        H' * Î£Vinv * H * A * Ï• * Ï•' +
        Î£Uinv  * A * Ï•_t * Ï•_t' -
        Î£Uinv * M * fcurr * Ï•_t' -
        reduce(vcat, [Ï•_t' * A'  * Î£Uinv * M * fprime[i] - (fcurr' * M' * Î£Uinv * M) * fprime[i] for i in 1:size(fprime,1)])

  return Î”L

end



"""
    update_A!(pars)

Updates ğ€ with the elastic net prior (Li 2010)

"""
function update_A!(pars, model)

  samp_inds = sample(model.inner_inds, model.batch_size, replace = false)

  v = model.V[:, samp_inds] # if an error occurs with 1D vs 2D space, it is here
  h = model.H[samp_inds]
  Ï• = model.Basis.TimeDerivative[model.Basis.TimeNames[1]][samp_inds, :]
  Ï•_t = model.Basis.TimeDerivative[model.Basis.TimeNames[end]][samp_inds, :]
  Î£Vinv = inv(pars.Î£V)
  Î£Uinv = inv(pars.Î£U)
  A = pars.A
  M = pars.M

  fcurr = pars.F[samp_inds,:]
  fprime = create_âˆ‡Î›(model.Î›, A, model.Basis, samp_inds, model.Î›TimeNames, model.X)

  dq = [Î”L(v[:, i], h[i], Ï•[i, :], Ï•_t[i, :], Î£Vinv, Î£Uinv, A, M, fcurr[i,:], fprime[i,:]) for i in 1:length(samp_inds)]

  scale_el = 1 / 100
  dq = mean(dq) + (1 / (model.T)) * (scale_el * sign.(A) + 2 * scale_el * A)


  # pars.A = A - model.learning_rate * dq
  pars.A = A - dq .* model.learning_rate

  # save updated state information
  pars.sample_inds = samp_inds
  pars.State = construct_state(pars.A, model.Basis)
  pars.F = create_Î›(model.Î›, pars.A, model.Basis, model.Î›TimeNames, model.X)
  pars.Fprime = fprime

  return pars
end


"""
    DEtection_sampler(Y, TimeStep, nbasis, buffer, batch_size, learning_rate, v0, v1, Î›, Î›names)

DEtection sampler function. Can accept missing values in the input data argument.
Returns the model, parameters, and posterior values.
The model are the model settings.
The parameters are the final value of the parameters in from the sampler.
The posterior are the saved posterior values.

Consider the function ``U_t = M(U, U^2, U^3, ...)``.
DEtection_sampler() is used to determine ``M`` given a library of potential values, `Î›(U)`, to search over. 
Within the function, derivatives are denoted as ``Î”U_t, Î”U_tt, ...``, so a potential function could be

```jldoctest 
Î›Names = ["Phi"]

function Î›(A, Î¦)
    
  Ï• = Î¦[1]
  u = A * Ï•'

  X = u[1,:]
  Y = u[2,:]
  Z = u[3,:]
  
  return [X, Y, Z, X .* Y, X .* Z, Y .* Z, X.^2, Y.^2, Z.^2, X.^2 .* Y, X .* Y.^2, X.^2 .* Z, X .* Z.^2, Y.^2 .* Z, Y .* Z.^2, X.^3, Y.^3, Z.^3, X .* Y .* Z]

end
```

The function must take in ``A`` and ``Î¦``, where ``Î¦`` is a vector of the basis functions.

To make the function identify the correct partial derivatives, the arguments that are passed into `Î›`, `Î›names`, are required where.
For the example above, `Î›names = ["Phi"]` because the function `Î›` does not take any higher order derivatives.
If the function accepted higher order derivatives,  `Î›names = ["Phi", "Phi_t", ...]`.


# Required Arguments (in order)
- `Y`: Input data. Needs to be Array{Float64, 2} or Array{Union{Missing, Float64}, 2} where the dimensions are Components by Time
- `TimeStep`: of type Vector()
- `nbasis::Int`: Number of temporal basis functions
- `buffer::Int`: Buffer on each side of the data to negate edge effects
- `batch_size::Int`: size of the minibatch
- `learning_rate::Float64`: Learning rate for the stochastic gradient descent with constant learning rate
- `v0::Float64`: SSVS exclusion variance
- `v1::Float64`: SSVS inclusion variance
- `Î›::Function`: Library to search over
- `Î›names::Vector{String}`: Names of derivatives of library (see example)

# Optional Arguments
- `degree` = 4: Degree of the B-spline. Must be at least one order higher than the highest order partial derivative.
- `orderTime` = 1: Order of the highest order temporal derivative (default U_t)
- `latent_dim` = size(Y, 1): Dimension of the latent space. Default is same as data dimension.
- `covariates` = nothing: Additional covariates.
- `nits` = 2000: Number of samples for the Gibbs sampler.
- `burnin` = nits / 2: Number of samples to discard as burnin (default is half of `nits`).
- `learning_rate_end` = learning_rate: End learning rate (default is same as initial learning rate).


# Examples

```jldoctest 
Y = Array{Float64}(rand, 3, 1000) # component (3) by time (1000)
TimeStep = Vector(range(0.01, end_time, step = 0.01))
batch_size = 50
buffer = 20
v0 = 1e-6
v1 = 1e4
order = 1
learning_rate = 1e1

Î›names = ["Phi"]

function Î›(A, Î¦)
    
  Ï• = Î¦[1]
  u = A * Ï•'

  X = u[1,:]
  Y = u[2,:]
  Z = u[3,:]
  
  return [X, Y, Z, X .* Y, X .* Z, Y .* Z, X.^2, Y.^2, Z.^2, X.^2 .* Y, X .* Y.^2, X.^2 .* Z, X .* Z.^2, Y.^2 .* Z, Y .* Z.^2, X.^3, Y.^3, Z.^3, X .* Y .* Z]

end

# not run
# model, pars, posterior = DEtection_sampler(Y, TimeStep, nbasis, buffer, batch_size, learning_rate, v0, v1, Î›, Î›Names, nits = 2000)
``` 

# Example Higher Order Library

```jldoctest 
Î›Names = ["Phi", "Phi_t"]

function Î›(A, Î¦)
    
  Ï• = Î¦[1] # corresponds to no derivative
  Ï•t = Î¦[2] # corresponds to first derivative
  x = (A * Ï•')'
  xt = (A * Ï•t')'
  
  return [x, sin.(x), cos.(x), x ./ sin.(x), x ./ cos.(x), xt, xt.^2, xt .* sin.(x), xt .* cos.(x), sin.(xt), cos.(xt)]
  
end
``` 
"""
function DEtection_sampler(Y,
  TimeStep::Vector,
  nbasis::Int,
  buffer::Int,
  batch_size::Int,
  learning_rate::Float64,
  v0::Float64,
  v1::Float64,
  Î›::Function,
  Î›Names::Vector{String};
  degree = 4, orderTime = 1, latent_dim = size(Y, 1), covariates = nothing, nits = 2000, burnin = nits / 2, learning_rate_end = learning_rate)
  
  pars, model = create_pars(Y, TimeStep, nbasis, buffer, batch_size, learning_rate, v0, v1, Î›, Î›Names, degree = degree, orderTime = orderTime, latent_dim = latent_dim, covariates = covariates)

  keep_samps = Int(nits - burnin)
  n_change = log10(learning_rate / learning_rate_end)
  if n_change == 0
    change_times = 0.0
  else
    change_times = floor.(collect(range(1, stop=burnin, length=Int((n_change + 1)))))[2:end]
  end

  M_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  gamma_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  Î£V_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  Î£U_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  A_post = Array{Float64}(undef, model.N, size(pars.A)[2], keep_samps)
  Ï€_post = Array{Float64}(undef, model.N, keep_samps)


  @showprogress 1 "Burnin..." for i in 1:burnin

    pars = update_M!(pars, model)
    pars = update_gamma!(pars, model)
    pars = update_Î£V!(pars, model)
    pars = update_Î£U!(pars, model)
    pars = update_A!(pars, model)

    if i in change_times
      raise_pow = findall(change_times .== i)[1]
      model.learning_rate = round(learning_rate * 10.0^(-raise_pow), digits = raise_pow+6)
    end

  end

  @showprogress 1 "Sampling..." for i in 1:keep_samps

    pars = update_M!(pars, model)
    pars = update_gamma!(pars, model)
    pars = update_Î£V!(pars, model)
    pars = update_Î£U!(pars, model)
    pars = update_A!(pars, model)

    M_post[:, :, i] = pars.M
    gamma_post[:, :, i] = pars.gamma
    Î£V_post[:, :, i] = pars.Î£V
    Î£U_post[:, :, i] = pars.Î£U
    A_post[:, :, i] = pars.A
    Ï€_post[:,i] = pars.Ï€

  end

  posterior = Posterior(M_post, gamma_post, Î£V_post, Î£U_post, A_post, Ï€_post)

  return model, pars, posterior

end # 1 spatial dimension DEtection
